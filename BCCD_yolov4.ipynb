{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/AlicjaA/aa-yolo/blob/master/BCCD_yolov4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import urllib\n",
    "\n",
    "user = input('User name: ')\n",
    "password = getpass('Password: ')\n",
    "password = urllib.parse.quote(password) # your password is converted into url format\n",
    "repo_name = input('Repo name: ')\n",
    "mail = input('Mail: ')\n",
    "\n",
    "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
    "\n",
    "os.system(cmd_string)\n",
    "cmd_string, password = \"\", \"\" # removing the password from the variable\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('{2}/')\n",
    "\n",
    "!git config --global user.email '{3}'\n",
    "!git config --global user.name '{0}'\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting VOC to YOLO annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corected conversion - working\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "annotations = sorted(glob('../BCCD/Annotations/*.xml'))\n",
    "def blood_cells_types(argument): \n",
    "    switcher = { \n",
    "        'RBC':0,\n",
    "        'WBC':1, \n",
    "        'Platelets':2, \n",
    "    } \n",
    "    return switcher.get(argument, 0) \n",
    "\n",
    "df = []\n",
    "\n",
    "for file in annotations:\n",
    "    counter = 0\n",
    "    prev_filename = file.split('/')[-1].split('.')[0] + '.jpg'\n",
    "    row=''\n",
    "    parsedXML = ET.parse(file)  \n",
    "    width = int(parsedXML.getroot().find('size/width').text)\n",
    "    hight = int(parsedXML.getroot().find('size/height').text)\n",
    "    for node in parsedXML.getroot().iter('object'):\n",
    "        blood_cells = str(int(blood_cells_types(node.find('name').text)))\n",
    "        xmin = int(node.find('bndbox/xmin').text)\n",
    "        xmax = int(node.find('bndbox/xmax').text)\n",
    "        ymin = int(node.find('bndbox/ymin').text)\n",
    "        ymax = int(node.find('bndbox/ymax').text)\n",
    "        dw = 1./(width)\n",
    "        dh = 1./(hight)\n",
    "        x = (xmin + xmax)/2.0 - 1\n",
    "        y = (ymin + ymax)/2.0 - 1\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        x = x*dw\n",
    "        w = w*dw\n",
    "        y = y*dh\n",
    "        h = h*dh\n",
    "        if(counter==0):\n",
    "            row = prev_filename +' ' + blood_cells+',' + str(x)+',' + str(y)+',' + str(w)+',' + str(h)\n",
    "        else:\n",
    "            row+=' '+blood_cells+',' + str(x)+',' + str(y)+',' + str(w)+',' + str(h)\n",
    "        counter+=1\n",
    "    df.append(row)\n",
    "    row =''\n",
    "\n",
    "data = pd.DataFrame(data=df)\n",
    "\n",
    "data.to_csv('./blood_cell_detection3.txt', index=False, header=None)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing converted annotations on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data with bbox\n",
    "\"\"\"\n",
    "TODO:\n",
    "plot more tkan one image\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from py_src.yolov4.tf import YOLOv4\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "yolo = YOLOv4()\n",
    "yolo.classes = \"./test/dataset/bccd.names\"\n",
    "yolo.input_size = (640, 480)\n",
    "yolo.batch_size = 2\n",
    "dataset = yolo.load_dataset(\"./test/dataset/bccd_test.txt\", image_path_prefix=\"./test/dataset/JPEGImages/\")\n",
    "images_to_show=[]\n",
    "for i, (images, gt) in enumerate(dataset):\n",
    "    for j in range(len(images)):\n",
    "        _candidates = []\n",
    "        for candidate in gt:\n",
    "            grid_size = candidate.shape[1:3]\n",
    "            _candidates.append(\n",
    "                tf.reshape(\n",
    "                    candidate[j], shape=(1, grid_size[0] * grid_size[1] * 3, -1)\n",
    "                )\n",
    "            )\n",
    "        candidates = np.concatenate(_candidates, axis=1)\n",
    "\n",
    "        frame = images[j, ...] * 255\n",
    "        frame = frame.astype(np.uint8)\n",
    "\n",
    "        pred_bboxes = yolo.candidates_to_pred_bboxes(candidates[0])\n",
    "        pred_bboxes = yolo.fit_pred_bboxes_to_original(pred_bboxes, frame.shape)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        image = yolo.draw_bboxes(frame, pred_bboxes)\n",
    "        images_to_show.append(image)\n",
    "    if i == 10:\n",
    "        break\n",
    "for image in images_to_show:\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning on BCCD images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with transfer learning\n",
    "import sys\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from py_src.yolov4.tf import SaveWeightsCallback, YOLOv4\n",
    "import time\n",
    "\n",
    "yolo = YOLOv4(tiny=True)\n",
    "yolo.classes = \"./test/dataset/bccd.names\"\n",
    "yolo.input_size = 640,480\n",
    "yolo.batch_size = 32\n",
    "\n",
    "yolo.make_model()\n",
    "yolo.model_summary()\n",
    "yolo.load_weights(\n",
    "    \"./test/yolov4-tiny.conv.29\",\n",
    "    weights_type=\"yolo\"\n",
    ")\n",
    "\n",
    "train_data_set = yolo.load_dataset( \"./test/dataset/bccd_test.txt\", image_path_prefix=\"./test/dataset/JPEGImages/\", label_smoothing=0.05)\n",
    "\n",
    "val_data_set = yolo.load_dataset( \"./test/dataset/bccd_val.txt\", image_path_prefix=\"./test/dataset/JPEGImages/\",training=False)\n",
    "\n",
    "epochs = 10\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=lr)\n",
    "yolo.compile(optimizer=optimizer, loss_iou_type=\"ciou\")\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < int(epochs * 0.5):\n",
    "        return lr\n",
    "    if epoch < int(epochs * 0.8):\n",
    "        return lr * 0.5\n",
    "    if epoch < int(epochs * 0.9):\n",
    "        return lr * 0.1\n",
    "    return lr * 0.01\n",
    "\n",
    "_callbacks = [\n",
    "    callbacks.LearningRateScheduler(lr_scheduler),\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=\"./test/logs\", histogram_freq=1\n",
    "    ),\n",
    "    SaveWeightsCallback(\n",
    "        yolo=yolo, dir_path=\"./test/weights\",\n",
    "        weights_type=\"yolo\", epoch_per_save=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "yolo.fit(\n",
    "    train_data_set,\n",
    "    epochs=epochs,\n",
    "    callbacks=_callbacks,\n",
    "    validation_data=val_data_set,\n",
    "    validation_steps=50,\n",
    "    validation_freq=5,\n",
    "    steps_per_epoch=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating test model from learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate tests\n",
    "from py_src.yolov4.tf import YOLOv4\n",
    "\n",
    "yolo = YOLOv4(tiny=True, tpu=True)\n",
    "\n",
    "yolo.classes = \"./test/dataset/bccd.names\"\n",
    "\n",
    "yolo.make_model(activation1=\"relu\")\n",
    "yolo.load_weights(\"./test/weights/yolov4-tiny-final-bccd.weights\", weights_type=\"yolo\")\n",
    "\n",
    "dataset = yolo.load_dataset( \"./test/dataset/bccd_val.txt\", image_path_prefix=\"./test/dataset/JPEGImages/\",training=False)\n",
    "\n",
    "yolo.save_as_tflite(\n",
    "    \"yolov4_640x480-bccd.tflite\",\n",
    "    quantization=\"full_int8\",\n",
    "    data_set=dataset,\n",
    "    num_calibration_steps=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing results on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "from py_src.yolov4.tflite import YOLOv4\n",
    "\n",
    "yolo = YOLOv4()\n",
    "\n",
    "yolo.classes = \"./test/dataset/bccd.names\"\n",
    "\n",
    "yolo.load_tflite(\"yolov4_640x480-bccd.tflite\")\n",
    "\n",
    "yolo.inference(\"BloodImage_00000.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
